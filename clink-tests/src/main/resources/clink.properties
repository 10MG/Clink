# Flink 集群配置
rest.address=127.0.0.1
rest.connection-timeout=3000
# 只重试一次（默认值为20），以避免某些节点宕机后重试时间过长
rest.retry.max-attempts=1

#security.ssl.rest.enabled: true
security.ssl.rest.keystore: C:/Users/admin/flink-1.18.1/conf/rest.signed.keystore
security.ssl.rest.truststore: C:/Users/admin/flink-1.18.1/conf/ca.truststore
security.ssl.rest.keystore-password: rest_keystore_password
security.ssl.rest.key-password: rest_keystore_password
security.ssl.rest.truststore-password: ca_truststore_password
security.ssl.rest.authentication-enabled: true

#Flink Table API配置
#空值处理配置
table.exec.sink.not-null-enforcer=drop

#数据同步自动添加的列
data.sync.auto-columns=op,event_timestamp,etl_timestamp,ingestion_timestamp
#数据同步自动添加EVENT_TIMESTAMP时间戳列的类型配置
data.sync.event_timestamp.from-type=TIMESTAMP_LTZ(3) METADATA FROM 'op_ts' VIRTUAL
data.sync.event_timestamp.to-type=TIMESTAMP(3)
data.sync.op.from-type=CHAR(1) METADATA FROM 'op' VIRTUAL
#ETL_TIMESTAMP列取当前时间戳，策略设置为to，仅创建目标列而不创建来源列
data.sync.etl_timestamp.strategy=to
data.sync.etl_timestamp.script=CURRENT_TIMESTAMP
data.sync.ingestion_timestamp.from-type=TIMESTAMP_LTZ(3) METADATA FROM 'igs_ts' VIRTUAL
data.sync.ingestion_timestamp.to-type=TIMESTAMP(3)

#配置名称为mysql-cdc的数据源
datasource.mysql-cdc.connector=mysql-cdc
datasource.mysql-cdc.server-time-zone=Asia/Shanghai
datasource.mysql-cdc.hostname=localhost
datasource.mysql-cdc.port=3306
datasource.mysql-cdc.database-name=test
datasource.mysql-cdc.username=${mysql.username}
datasource.mysql-cdc.password=${mysql.password}
#配置名称为mysql-jdbc的数据源
datasource.mysql-jdbc.connector=jdbc
datasource.mysql-jdbc.driver=com.mysql.cj.jdbc.Driver
datasource.mysql-jdbc.url=jdbc:mysql://localhost:3306/test?useSSL=false&serverTimezone=GMT%2B8&autoReconnect=true
datasource.mysql-jdbc.username=${mysql.username}
datasource.mysql-jdbc.password=${mysql.password}

#配置名称为postgresql-cdc的数据源
datasource.postgresql-cdc.connector=postgres-cdc
datasource.postgresql-cdc.hostname=localhost
datasource.postgresql-cdc.port=5432
datasource.postgresql-cdc.database-name=test
datasource.postgresql-cdc.username=${postgresql.username}
datasource.postgresql-cdc.password=${postgresql.password}
#配置名称为postgresql-jdbc的数据源
datasource.postgresql-jdbc.connector=jdbc
datasource.postgresql-jdbc.driver=org.postgresql.Driver
datasource.postgresql-jdbc.url=jdbc:postgresql://localhost:5432/test
datasource.postgresql-jdbc.username=${postgresql.username}
datasource.postgresql-jdbc.password=${postgresql.password}

#配置名称为sqlserver-cdc的数据源
datasource.sqlserver-cdc.connector=sqlserver-cdc
datasource.sqlserver-cdc.server-time-zone=Asia/Shanghai
datasource.sqlserver-cdc.hostname=localhost
datasource.sqlserver-cdc.port=1433
datasource.sqlserver-cdc.database-name=test
datasource.sqlserver-cdc.username=${sqlserver.username}
datasource.sqlserver-cdc.password=${sqlserver.password}
#配置名称为sqlserver-jdbc的数据源
datasource.sqlserver-jdbc.connector=jdbc
datasource.sqlserver-jdbc.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
datasource.sqlserver-jdbc.url=jdbc:sqlserver://localhost:1433;DatabaseName=test
datasource.sqlserver-jdbc.username=${sqlserver.username}
datasource.sqlserver-jdbc.password=${sqlserver.password}

#配置名称为oracle-cdc的数据源
datasource.oracle-cdc.connector=oracle-cdc
datasource.oracle-cdc.hostname=localhost
datasource.oracle-cdc.port=1521
datasource.oracle-cdc.database-name=ORCL
datasource.oracle-cdc.schema-name=${oracle.schema}
datasource.oracle-cdc.username=${oracle.username}
datasource.oracle-cdc.password=${oracle.password}
datasource.oracle-cdc.debezium.log.mining.strategy=online_catalog

#配置名称为oracle-jdbc的数据源
datasource.oracle-jdbc.connector=jdbc
datasource.oracle-jdbc.driver=oracle.jdbc.OracleDriver
datasource.oracle-jdbc.url=jdbc:oracle:thin:@localhost:1521:ORCL
datasource.oracle-jdbc.username=${oracle.username}
datasource.oracle-jdbc.password=${oracle.password}

#配置名称为kafka-json的数据源
datasource.kafka-json.connector=kafka
datasource.kafka-json.properties.bootstrap.servers=localhost:9092
datasource.kafka-json.properties.group.id=Clink
datasource.kafka-json.scan.startup.mode=earliest-offset
datasource.kafka-json.format=json
datasource.kafka-json.json.fail-on-missing-field=false

#配置名称为kafka-csv的数据源
datasource.kafka-csv.connector=kafka
datasource.kafka-csv.properties.bootstrap.servers=localhost:9092
datasource.kafka-csv.properties.group.id=Clink
datasource.kafka-csv.scan.startup.mode=earliest-offset
datasource.kafka-csv.format=csv
datasource.kafka-csv.csv.ignore-parse-errors=false
datasource.kafka-csv.csv.allow-comments=true

#配置名称为kafka-avro的数据源
datasource.kafka-avro.connector=kafka
datasource.kafka-avro.properties.bootstrap.servers=localhost:9092
datasource.kafka-avro.properties.group.id=Clink
datasource.kafka-avro.scan.startup.mode=earliest-offset
datasource.kafka-avro.format=avro

#配置名称为kafka-avro-confluent的数据源
datasource.kafka-avro-confluent.connector=kafka
datasource.kafka-avro-confluent.properties.bootstrap.servers=localhost:9092
datasource.kafka-avro-confluent.properties.group.id=Clink
datasource.kafka-avro-confluent.scan.startup.mode=earliest-offset
datasource.kafka-avro-confluent.key.format=raw
datasource.kafka-avro-confluent.key.fields=id
datasource.kafka-avro-confluent.value.format=avro-confluent
datasource.kafka-avro-confluent.value.avro-confluent.url=http://localhost:8082
datasource.kafka-avro-confluent.value.fields-include=EXCEPT_KEY

#配置名称为kafka-protobuf的数据源
datasource.kafka-protobuf.connector=kafka
datasource.kafka-protobuf.properties.bootstrap.servers=localhost:9092
datasource.kafka-protobuf.properties.group.id=Clink
datasource.kafka-protobuf.scan.startup.mode=earliest-offset
datasource.kafka-protobuf.format=protobuf
datasource.kafka-protobuf.protobuf.message-class-name=cn.tenmg.SimpleTest
datasource.kafka-protobuf.protobuf.ignore-parse-errors=true

#配置名称为kafka-debezium-json的数据源
datasource.kafka-debezium-json.connector=kafka
datasource.kafka-debezium-json.properties.bootstrap.servers=localhost:9092
datasource.kafka-debezium-json.properties.group.id=Clink
datasource.kafka-debezium-json.scan.startup.mode=earliest-offset
datasource.kafka-debezium-json.format=debezium-json

#配置名称为kafka-debezium-avro-confluent的数据源
datasource.kafka-debezium-avro-confluent.connector=kafka
datasource.kafka-debezium-avro-confluent.properties.bootstrap.servers=localhost:9092
datasource.kafka-debezium-avro-confluent.properties.group.id=Clink
datasource.kafka-debezium-avro-confluent.scan.startup.mode=earliest-offset
datasource.kafka-debezium-avro-confluent.format=debezium-avro-confluent
datasource.kafka-debezium-avro-confluent.debezium-avro-confluent.url=http://localhost:8081

#配置名称为kafka-canal-json的数据源
datasource.kafka-canal-json.connector=kafka
datasource.kafka-canal-json.properties.bootstrap.servers=localhost:9092
datasource.kafka-canal-json.properties.group.id=Clink
datasource.kafka-canal-json.scan.startup.mode=earliest-offset
datasource.kafka-canal-json.format=canal-json

#配置名称为kafka-maxwell-json的数据源
datasource.kafka-maxwell-json.connector=kafka
datasource.kafka-maxwell-json.properties.bootstrap.servers=localhost:9092
datasource.kafka-maxwell-json.properties.group.id=Clink
datasource.kafka-maxwell-json.scan.startup.mode=earliest-offset
datasource.kafka-maxwell-json.format=maxwell-json

#配置名称为kafka-ogg-json的数据源
datasource.kafka-ogg-json.connector=kafka
datasource.kafka-ogg-json.properties.bootstrap.servers=localhost:9092
datasource.kafka-ogg-json.properties.group.id=Clink
datasource.kafka-ogg-json.scan.startup.mode=earliest-offset
datasource.kafka-ogg-json.format=ogg-json

#配置名称为kafka-raw的数据源
datasource.kafka-raw.connector=kafka
datasource.kafka-raw.properties.bootstrap.servers=localhost:9092
datasource.kafka-raw.properties.group.id=Clink
datasource.kafka-raw.scan.startup.mode=earliest-offset
datasource.kafka-raw.format=raw